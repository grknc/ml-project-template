{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Feature Engineering\n",
        "\n",
        "Transform raw/clean data into model-ready features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives\n",
        "- Separate features and target\n",
        "- Build preprocessing pipelines\n",
        "- Save processed datasets or fitted transformers\n",
        "\n",
        "> **Learner task:** Add domain-specific feature logic (aggregations, date features, interactions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load cleaned data\n",
        "# TODO: Replace with your processed/cleaned dataset\n",
        "df = pd.read_csv(\"data/processed/sample_clean.csv\")\n",
        "\n",
        "target_col = \"target\"  # TODO: update target column\n",
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify feature types\n",
        "numeric_features = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
        "\n",
        "print(\"Numeric features:\", numeric_features)\n",
        "print(\"Categorical features:\", categorical_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build preprocessing pipeline\n",
        "numeric_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "categorical_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_pipeline, numeric_features),\n",
        "        (\"cat\", categorical_pipeline, categorical_features),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit-transform features\n",
        "X_transformed = preprocessor.fit_transform(X)\n",
        "print(\"Transformed shape:\", X_transformed.shape)\n",
        "\n",
        "# TODO: Save transformed features if needed\n",
        "# Example:\n",
        "# import joblib\n",
        "# joblib.dump(preprocessor, \"models/preprocessor.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering Notes\n",
        "- New engineered features:\n",
        "- Features dropped and why:\n",
        "- Assumptions made:"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}