{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00",
   "metadata": {},
   "source": "# Customer Segmentation with Clustering\n\nSegment customers into meaningful groups using unsupervised clustering.\n\n**Dataset:** [https://www.kaggle.com/datasets/yasserh/customer-segmentation-dataset/data](https://www.kaggle.com/datasets/yasserh/customer-segmentation-dataset/data)  \n**Type:** Unsupervised Clustering\n\n> **TODO:** Download the dataset, place it in `../../data/raw/`, then update `DATA_PATH` below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score\nfrom sklearn.impute import SimpleImputer\nsns.set_theme(style='whitegrid')"
  },
  {
   "cell_type": "markdown",
   "id": "c02",
   "metadata": {},
   "source": "## 1. Load Data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03",
   "metadata": {},
   "outputs": [],
   "source": "DATA_PATH = \"../../data/raw/customers.csv\"\n\ndf = pd.read_csv(DATA_PATH)\nprint(f'Shape: {df.shape}')\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "c04",
   "metadata": {},
   "source": "## 2. EDA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05",
   "metadata": {},
   "outputs": [],
   "source": "print(df.info())\nprint('\\nNull counts:')\nprint(df.isnull().sum())\ndf.describe().T"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06",
   "metadata": {},
   "outputs": [],
   "source": "# Pairplot of numeric features (sample if large)\nnum_df = df.select_dtypes(include='number')\nsample = num_df.sample(min(500, len(num_df)), random_state=42)\nsns.pairplot(sample, diag_kind='kde', plot_kws={'alpha': 0.3, 's': 10})\nplt.suptitle('Feature Pairplot', y=1.01)\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c07",
   "metadata": {},
   "source": "## 3. Feature Selection & Scaling"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: Select relevant features for clustering\n# Drop ID / date columns if present\nfeature_cols = df.select_dtypes(include='number').columns.tolist()\n# feature_cols = ['col1', 'col2', ...]  # or specify manually\n\nX = df[feature_cols].copy()\nX = SimpleImputer(strategy='median').fit_transform(X)\nX_scaled = StandardScaler().fit_transform(X)\nprint(f'Feature matrix shape: {X_scaled.shape}')"
  },
  {
   "cell_type": "markdown",
   "id": "c09",
   "metadata": {},
   "source": "## 4. Determine Optimal K"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10",
   "metadata": {},
   "outputs": [],
   "source": "inertias, silhouettes = [], []\nK_range = range(2, 11)\n\nfor k in K_range:\n    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n    labels = km.fit_predict(X_scaled)\n    inertias.append(km.inertia_)\n    silhouettes.append(silhouette_score(X_scaled, labels))\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\naxes[0].plot(list(K_range), inertias, 'bo-')\naxes[0].set_title('Elbow Method'); axes[0].set_xlabel('k')\naxes[1].plot(list(K_range), silhouettes, 'ro-')\naxes[1].set_title('Silhouette Score'); axes[1].set_xlabel('k')\nplt.tight_layout(); plt.show()\n\nbest_k = list(K_range)[silhouettes.index(max(silhouettes))]\nprint(f'Best k by silhouette: {best_k}')"
  },
  {
   "cell_type": "markdown",
   "id": "c11",
   "metadata": {},
   "source": "## 5. Final Clustering"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12",
   "metadata": {},
   "outputs": [],
   "source": "K = best_k  # TODO: override if domain knowledge suggests otherwise\n\nkm_final = KMeans(n_clusters=K, random_state=42, n_init=10)\ndf['cluster'] = km_final.fit_predict(X_scaled)\n\nsil = silhouette_score(X_scaled, df['cluster'])\ndb = davies_bouldin_score(X_scaled, df['cluster'])\nprint(f'Silhouette Score: {sil:.4f}')\nprint(f'Davies-Bouldin Score: {db:.4f}  (lower is better)')\nprint(df['cluster'].value_counts())"
  },
  {
   "cell_type": "markdown",
   "id": "c13",
   "metadata": {},
   "source": "## 6. PCA Visualisation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14",
   "metadata": {},
   "outputs": [],
   "source": "pca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\nexplained = pca.explained_variance_ratio_.sum()\n\nplt.figure(figsize=(8, 6))\nscatter = plt.scatter(X_pca[:, 0], X_pca[:, 1],\n                     c=df['cluster'], cmap='tab10', alpha=0.6, s=15)\nplt.colorbar(scatter, label='Cluster')\nplt.title(f'PCA Projection â€” {K} Clusters (var explained: {explained:.1%})')\nplt.xlabel('PC1'); plt.ylabel('PC2')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c15",
   "metadata": {},
   "source": "## 7. Segment Profiles"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16",
   "metadata": {},
   "outputs": [],
   "source": "cluster_profile = df.groupby('cluster')[feature_cols].mean().T\ncluster_profile.columns = [f'Cluster {c}' for c in cluster_profile.columns]\nprint(cluster_profile.round(2))\n\n# Heatmap\nplt.figure(figsize=(10, max(4, len(feature_cols) * 0.4)))\nsns.heatmap(cluster_profile, cmap='RdYlGn', annot=True, fmt='.2f', linewidths=0.5)\nplt.title('Cluster Profiles (mean feature values)')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c17",
   "metadata": {},
   "source": "## 8. Conclusion\n\n| Cluster | Size | Interpretation |\n|---|---|---|\n| *(fill after running)* | | |\n\n**Observations:**\n- \n\n**Next steps:**\n- Try DBSCAN for density-based clustering\n- Add categorical features via Gower distance\n- Use clusters for downstream classification/regression tasks"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}