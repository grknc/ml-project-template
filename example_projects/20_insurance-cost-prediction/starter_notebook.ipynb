{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00",
   "metadata": {},
   "source": "# Insurance Premium Cost Prediction\n\nPredict medical insurance charges from age, BMI, smoking status, and region.\n\n**Dataset:** [https://www.kaggle.com/datasets/mirichoi0218/insurance](https://www.kaggle.com/datasets/mirichoi0218/insurance)  \n**Target:** `charges`  \n**Type:** Regression\n\n> **TODO:** Download the dataset, place it in `../../data/raw/`, then update `DATA_PATH` and `TARGET` below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nsns.set_theme(style='whitegrid')"
  },
  {
   "cell_type": "markdown",
   "id": "c02",
   "metadata": {},
   "source": "## 1. Load Data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: update path after downloading from https://www.kaggle.com/datasets/mirichoi0218/insurance\nDATA_PATH = \"../../data/raw/insurance.csv\"\nTARGET = \"charges\"  # TODO: verify column name\n\ndf = pd.read_csv(DATA_PATH)\nprint(f'Shape: {df.shape}')\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "c04",
   "metadata": {},
   "source": "## 2. Exploratory Data Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05",
   "metadata": {},
   "outputs": [],
   "source": "print(df.info())\nprint('\\nNull counts:')\nprint(df.isnull().sum().sort_values(ascending=False).head(15))\ndf.describe().T"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06",
   "metadata": {},
   "outputs": [],
   "source": "# Target distribution\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\ndf[TARGET].hist(bins=40, ax=axes[0])\naxes[0].set_title(f'Distribution: {TARGET}')\nnp.log1p(df[TARGET]).hist(bins=40, ax=axes[1])\naxes[1].set_title(f'Log Distribution: {TARGET}')\nplt.tight_layout(); plt.show()\nprint(df[TARGET].describe())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07",
   "metadata": {},
   "outputs": [],
   "source": "# Correlation with target\nnum_df = df.select_dtypes(include='number')\ncorr = num_df.corr()[TARGET].drop(TARGET).sort_values()\ncorr.plot(kind='barh', figsize=(8, max(4, len(corr) * 0.3)))\nplt.title(f'Feature Correlation with {TARGET}')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c08",
   "metadata": {},
   "source": "## 3. Feature Engineering"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09",
   "metadata": {},
   "outputs": [],
   "source": "X = df.drop(columns=[TARGET])\ny = df[TARGET]\n\n# Optional: log-transform skewed target\n# y = np.log1p(y)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns.tolist()\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n\nnumeric_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler()),\n])\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n])\npreprocessor = ColumnTransformer([\n    ('num', numeric_pipeline, numeric_cols),\n    ('cat', categorical_pipeline, categorical_cols),\n])"
  },
  {
   "cell_type": "markdown",
   "id": "c10",
   "metadata": {},
   "source": "## 4. Train / Test Split"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11",
   "metadata": {},
   "outputs": [],
   "source": "X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\nprint(f'Train: {X_train.shape}, Test: {X_test.shape}')"
  },
  {
   "cell_type": "markdown",
   "id": "c12",
   "metadata": {},
   "source": "## 5. Model Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13",
   "metadata": {},
   "outputs": [],
   "source": "def eval_reg(name, pipe, X_tr, X_te, y_tr, y_te):\n    pipe.fit(X_tr, y_tr)\n    preds = pipe.predict(X_te)\n    mae = mean_absolute_error(y_te, preds)\n    rmse = np.sqrt(mean_squared_error(y_te, preds))\n    r2 = r2_score(y_te, preds)\n    print(f'{name}: MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.4f}')\n    return pipe, preds, {'mae': mae, 'rmse': rmse, 'r2': r2}\n\nmodels = {\n    'Linear Regression': Pipeline([('pre', preprocessor), ('reg', LinearRegression())]),\n    'Ridge': Pipeline([('pre', preprocessor), ('reg', Ridge(alpha=1.0))]),\n    'Random Forest': Pipeline([('pre', preprocessor),\n                              ('reg', RandomForestRegressor(n_estimators=100, random_state=42))]),\n    'Gradient Boosting': Pipeline([('pre', preprocessor),\n                                  ('reg', GradientBoostingRegressor(n_estimators=100, random_state=42))]),\n}\n\nresults = {}\nfor name, pipe in models.items():\n    fitted, preds, metrics = eval_reg(name, pipe, X_train, X_test, y_train, y_test)\n    results[name] = {'pipe': fitted, 'preds': preds, 'metrics': metrics}"
  },
  {
   "cell_type": "markdown",
   "id": "c14",
   "metadata": {},
   "source": "## 6. Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15",
   "metadata": {},
   "outputs": [],
   "source": "best_name = min(results, key=lambda k: results[k]['metrics']['rmse'])\nbest_preds = results[best_name]['preds']\nprint(f'Best model: {best_name}')\n\n# Actual vs Predicted\nfig, axes = plt.subplots(1, 2, figsize=(13, 5))\naxes[0].scatter(y_test, best_preds, alpha=0.4, s=15)\nlims = [min(y_test.min(), best_preds.min()), max(y_test.max(), best_preds.max())]\naxes[0].plot(lims, lims, 'r--')\naxes[0].set_xlabel('Actual'); axes[0].set_ylabel('Predicted')\naxes[0].set_title(f'Actual vs Predicted — {best_name}')\n\n# Residuals\nresiduals = y_test - best_preds\naxes[1].scatter(best_preds, residuals, alpha=0.4, s=15)\naxes[1].axhline(0, color='r', linestyle='--')\naxes[1].set_xlabel('Predicted'); axes[1].set_ylabel('Residual')\naxes[1].set_title('Residual Plot')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16",
   "metadata": {},
   "outputs": [],
   "source": "# Feature importances\nrf_pipe = results['Random Forest']['pipe']\nfeat_names = rf_pipe.named_steps['pre'].get_feature_names_out()\nimportances = pd.Series(\n    rf_pipe.named_steps['reg'].feature_importances_, index=feat_names\n)\nimportances.nlargest(15).sort_values().plot(kind='barh', figsize=(8, 5))\nplt.title('Top 15 Feature Importances (Random Forest)')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c17",
   "metadata": {},
   "source": "## 7. Conclusion\n\n| Model | MAE | RMSE | R² |\n|---|---|---|---|\n| *(fill after running)* | | | |\n\n**Observations:**\n- \n\n**Next steps:**\n- Log-transform skewed target if not done\n- Hyperparameter tuning\n- Try XGBoost / LightGBM"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}