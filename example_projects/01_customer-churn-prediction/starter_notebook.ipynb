{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00",
   "metadata": {},
   "source": "# Bank Customer Churn Prediction\n\nPredict whether a bank customer will leave based on their profile and account activity.\n\n**Dataset:** [https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data](https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data)  \n**Target:** `churn`  \n**Type:** Imbalanced Binary Classification\n\n> **TODO:** Download the dataset, place it in `../../data/raw/`, then update `DATA_PATH` and `TARGET` below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import (\n    classification_report, roc_auc_score,\n    roc_curve, ConfusionMatrixDisplay,\n)\nsns.set_theme(style='whitegrid')"
  },
  {
   "cell_type": "markdown",
   "id": "c02",
   "metadata": {},
   "source": "## 1. Load Data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03",
   "metadata": {},
   "outputs": [],
   "source": "# TODO: update path after downloading from https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data\nDATA_PATH = \"../../data/raw/bank_customer_churn.csv\"\nTARGET = \"churn\"  # TODO: verify column name\n\ndf = pd.read_csv(DATA_PATH)\nprint(f'Shape: {df.shape}')\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "c04",
   "metadata": {},
   "source": "## 2. Exploratory Data Analysis"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05",
   "metadata": {},
   "outputs": [],
   "source": "print(df.info())\nprint('\\nNull counts:')\nprint(df.isnull().sum().sort_values(ascending=False).head(15))\ndf.describe(include='all').T"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06",
   "metadata": {},
   "outputs": [],
   "source": "# Target distribution\nfig, ax = plt.subplots()\ndf[TARGET].value_counts().plot(kind='bar', ax=ax)\nax.set_title(f'Target distribution: {TARGET}')\nax.set_xlabel(TARGET); ax.set_ylabel('Count')\nplt.xticks(rotation=0)\nplt.tight_layout(); plt.show()\nprint(df[TARGET].value_counts(normalize=True).round(3))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07",
   "metadata": {},
   "outputs": [],
   "source": "# Correlation heatmap (numeric features)\nnum_df = df.select_dtypes(include='number')\nif len(num_df.columns) > 1:\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(num_df.corr(), annot=False, cmap='coolwarm', linewidths=0.5)\n    plt.title('Correlation Matrix')\n    plt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c08",
   "metadata": {},
   "source": "## 3. Feature Engineering"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09",
   "metadata": {},
   "outputs": [],
   "source": "X = df.drop(columns=[TARGET])\ny = df[TARGET]\n\n# TODO: encode binary string targets if needed, e.g.:\n# y = y.map({'Yes': 1, 'No': 0})\n\nnumeric_cols = X.select_dtypes(include=['number']).columns.tolist()\ncategorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\nprint('Numeric cols:', numeric_cols)\nprint('Categorical cols:', categorical_cols)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10",
   "metadata": {},
   "outputs": [],
   "source": "numeric_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler()),\n])\ncategorical_pipeline = Pipeline([\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n])\npreprocessor = ColumnTransformer([\n    ('num', numeric_pipeline, numeric_cols),\n    ('cat', categorical_pipeline, categorical_cols),\n])"
  },
  {
   "cell_type": "markdown",
   "id": "c11",
   "metadata": {},
   "source": "## 4. Train / Test Split"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12",
   "metadata": {},
   "outputs": [],
   "source": "X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(f'Train: {X_train.shape}, Test: {X_test.shape}')"
  },
  {
   "cell_type": "markdown",
   "id": "c13",
   "metadata": {},
   "source": "## 5. Model Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14",
   "metadata": {},
   "outputs": [],
   "source": "models = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42),\n    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n}\n\nresults = {}\nfor name, clf in models.items():\n    pipe = Pipeline([('preprocessor', preprocessor), ('clf', clf)])\n    pipe.fit(X_train, y_train)\n    preds = pipe.predict(X_test)\n    probs = pipe.predict_proba(X_test)[:, 1]\n    auc = roc_auc_score(y_test, probs)\n    results[name] = {'pipe': pipe, 'preds': preds, 'probs': probs, 'roc_auc': auc}\n    print(f'\\n=== {name} ===')\n    print(f'ROC-AUC: {auc:.4f}')\n    print(classification_report(y_test, preds))"
  },
  {
   "cell_type": "markdown",
   "id": "c15",
   "metadata": {},
   "source": "## 6. Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16",
   "metadata": {},
   "outputs": [],
   "source": "best_name = max(results, key=lambda k: results[k]['roc_auc'])\nbest = results[best_name]\nbest_probs = best['probs']\nprint(f'Best model: {best_name}  ROC-AUC: {best[\"roc_auc\"]:.4f}')\n\n# Precision-Recall AUC (better for imbalanced data)\nfrom sklearn.metrics import average_precision_score\npr_auc = average_precision_score(y_test, best_probs)\nprint(f\"PR-AUC: {pr_auc:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17",
   "metadata": {},
   "outputs": [],
   "source": "# Confusion Matrix\nConfusionMatrixDisplay.from_predictions(y_test, best['preds'])\nplt.title(f'Confusion Matrix â€” {best_name}')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18",
   "metadata": {},
   "outputs": [],
   "source": "# ROC Curves\nfig, ax = plt.subplots()\nfor name, res in results.items():\n    fpr, tpr, _ = roc_curve(y_test, res['probs'])\n    ax.plot(fpr, tpr, label=f\"{name} (AUC={res['roc_auc']:.3f})\")\nax.plot([0, 1], [0, 1], 'k--', label='Random')\nax.set_xlabel('False Positive Rate'); ax.set_ylabel('True Positive Rate')\nax.legend(); ax.set_title('ROC Curves')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19",
   "metadata": {},
   "outputs": [],
   "source": "# Feature importances (Random Forest)\nrf_pipe = results['Random Forest']['pipe']\nrf_clf = rf_pipe.named_steps['clf']\nfeat_names = (\n    rf_pipe.named_steps['preprocessor']\n    .get_feature_names_out()\n)\nimportances = pd.Series(rf_clf.feature_importances_, index=feat_names)\nimportances.nlargest(15).sort_values().plot(kind='barh', figsize=(8, 5))\nplt.title('Top 15 Feature Importances (Random Forest)')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c20",
   "metadata": {},
   "source": "## 7. Conclusion\n\n| Model | ROC-AUC |\n|---|---|\n| *(fill after running)* | |\n\n**Observations:**\n- \n\n**Next steps:**\n- Hyperparameter tuning (GridSearchCV / RandomizedSearchCV)\n- Try XGBoost / LightGBM\n- Threshold optimisation for Precision/Recall trade-off"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}