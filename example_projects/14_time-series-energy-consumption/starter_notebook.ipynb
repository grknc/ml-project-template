{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00",
   "metadata": {},
   "source": "# Energy Consumption Forecasting\n\nForecast household energy consumption using time series features.\n\n**Dataset:** [https://www.kaggle.com/datasets/uciml/electric-power-consumption-data-set](https://www.kaggle.com/datasets/uciml/electric-power-consumption-data-set)  \n**Target:** `Global_active_power`  \n**Type:** Time Series Forecasting\n\n> **TODO:** Download the dataset, place it in `../../data/raw/`, then update `DATA_PATH`, `DATE_COL`, and `TARGET` below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nsns.set_theme(style='whitegrid')"
  },
  {
   "cell_type": "markdown",
   "id": "c02",
   "metadata": {},
   "source": "## 1. Load & Parse Dates"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03",
   "metadata": {},
   "outputs": [],
   "source": "DATA_PATH = \"../../data/raw/household_power_consumption.txt\"\nDATE_COL = \"Date\"  # TODO: verify date column name\nTARGET = \"Global_active_power\"      # TODO: verify target column name\n\ndf = pd.read_csv(DATA_PATH, parse_dates=[DATE_COL])\ndf = df.sort_values(DATE_COL).reset_index(drop=True)\nprint(f'Shape: {df.shape}')\nprint(f'Date range: {df[DATE_COL].min()} → {df[DATE_COL].max()}')\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "c04",
   "metadata": {},
   "source": "## 2. Time Series EDA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05",
   "metadata": {},
   "outputs": [],
   "source": "# Overall trend\nplt.figure(figsize=(14, 4))\nplt.plot(df[DATE_COL], df[TARGET], linewidth=0.8)\nplt.title(f'{TARGET} over time')\nplt.xlabel(DATE_COL); plt.ylabel(TARGET)\nplt.tight_layout(); plt.show()\n\nprint(df[TARGET].describe())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06",
   "metadata": {},
   "outputs": [],
   "source": "# Seasonal patterns\ndf['year'] = df[DATE_COL].dt.year\ndf['month'] = df[DATE_COL].dt.month\ndf['dayofweek'] = df[DATE_COL].dt.dayofweek\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 4))\ndf.groupby('month')[TARGET].mean().plot(ax=axes[0])\naxes[0].set_title('Average by Month')\ndf.groupby('dayofweek')[TARGET].mean().plot(ax=axes[1])\naxes[1].set_title('Average by Day of Week')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c07",
   "metadata": {},
   "source": "## 3. Feature Engineering"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08",
   "metadata": {},
   "outputs": [],
   "source": "# Calendar features\ndf['quarter'] = df[DATE_COL].dt.quarter\ndf['weekofyear'] = df[DATE_COL].dt.isocalendar().week.astype(int)\n\n# Lag features — adjust window sizes to your data frequency\nfor lag in [1, 7, 14, 28]:\n    df[f'lag_{lag}'] = df[TARGET].shift(lag)\n\n# Rolling statistics\nfor window in [7, 14]:\n    df[f'rolling_mean_{window}'] = df[TARGET].shift(1).rolling(window).mean()\n    df[f'rolling_std_{window}'] = df[TARGET].shift(1).rolling(window).std()\n\ndf = df.dropna().reset_index(drop=True)\nprint(f'Shape after feature engineering: {df.shape}')"
  },
  {
   "cell_type": "markdown",
   "id": "c09",
   "metadata": {},
   "source": "## 4. Time-Based Train / Test Split"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10",
   "metadata": {},
   "outputs": [],
   "source": "# Use last 20% of time as test set (never shuffle time series!)\nsplit_idx = int(len(df) * 0.8)\ntrain_df = df.iloc[:split_idx]\ntest_df = df.iloc[split_idx:]\n\ndrop_cols = [TARGET, DATE_COL]\nfeature_cols = [c for c in df.columns if c not in drop_cols]\n\nX_train, y_train = train_df[feature_cols], train_df[TARGET]\nX_test, y_test = test_df[feature_cols], test_df[TARGET]\nprint(f'Train: {X_train.shape}, Test: {X_test.shape}')"
  },
  {
   "cell_type": "markdown",
   "id": "c11",
   "metadata": {},
   "source": "## 5. Model Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12",
   "metadata": {},
   "outputs": [],
   "source": "def mape(y_true, y_pred):\n    return np.mean(np.abs((y_true - y_pred) / np.where(y_true == 0, 1e-9, y_true))) * 100\n\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n}\n\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    mae = mean_absolute_error(y_test, preds)\n    rmse = np.sqrt(mean_squared_error(y_test, preds))\n    mp = mape(y_test.values, preds)\n    results[name] = {'model': model, 'preds': preds}\n    print(f'{name}: MAE={mae:.3f}  RMSE={rmse:.3f}  MAPE={mp:.2f}%')"
  },
  {
   "cell_type": "markdown",
   "id": "c13",
   "metadata": {},
   "source": "## 6. Forecast Plot"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14",
   "metadata": {},
   "outputs": [],
   "source": "best_name = min(\n    results,\n    key=lambda k: mean_squared_error(y_test, results[k]['preds'])\n)\nbest_preds = results[best_name]['preds']\n\nplt.figure(figsize=(14, 5))\nplt.plot(test_df[DATE_COL].values, y_test.values, label='Actual', linewidth=1)\nplt.plot(test_df[DATE_COL].values, best_preds, label=f'Predicted ({best_name})',\n         linewidth=1, linestyle='--')\nplt.title(f'Forecast vs Actual — {best_name}')\nplt.xlabel('Date'); plt.ylabel(TARGET)\nplt.legend(); plt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c15",
   "metadata": {},
   "source": "## 7. Conclusion\n\n| Model | MAE | RMSE | MAPE |\n|---|---|---|---|\n| *(fill after running)* | | | |\n\n**Observations:**\n- \n\n**Next steps:**\n- Add more lag windows\n- Try cross-validation with TimeSeriesSplit\n- Explore SARIMA / Prophet for pure time-series approaches"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}