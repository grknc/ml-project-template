{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00",
   "metadata": {},
   "source": "# Movie Review Sentiment Classification\n\nClassify movie reviews as positive or negative using TF-IDF.\n\n**Dataset:** [https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)  \n**Text column:** `review`  **Target:** `sentiment`  \n**Type:** Binary Text Classification\n\n> **TODO:** Download the dataset, place it in `../../data/raw/`, then update `DATA_PATH`, `TEXT_COL`, and `TARGET` below."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01",
   "metadata": {},
   "outputs": [],
   "source": "import re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import (\n    classification_report, ConfusionMatrixDisplay,\n    roc_auc_score, roc_curve,\n)\nsns.set_theme(style='whitegrid')"
  },
  {
   "cell_type": "markdown",
   "id": "c02",
   "metadata": {},
   "source": "## 1. Load Data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03",
   "metadata": {},
   "outputs": [],
   "source": "DATA_PATH = \"../../data/raw/IMDB Dataset.csv\"\nTEXT_COL = \"review\"  # TODO: verify column name\nTARGET = \"sentiment\"       # TODO: verify column name\n\ndf = pd.read_csv(DATA_PATH, encoding='latin-1')\ndf = df[[TEXT_COL, TARGET]].dropna()\nprint(f'Shape: {df.shape}')\nprint(df[TARGET].value_counts())\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "id": "c04",
   "metadata": {},
   "source": "## 2. EDA"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05",
   "metadata": {},
   "outputs": [],
   "source": "# Class distribution\ndf[TARGET].value_counts().plot(kind='bar')\nplt.title(f'Class Distribution: {TARGET}')\nplt.xticks(rotation=0); plt.tight_layout(); plt.show()\n\n# Text length\ndf['text_len'] = df[TEXT_COL].str.len()\ndf.groupby(TARGET)['text_len'].hist(alpha=0.6, bins=40)\nplt.title('Text Length by Class')\nplt.xlabel('Characters'); plt.tight_layout(); plt.show()\nprint(df.groupby(TARGET)['text_len'].describe())"
  },
  {
   "cell_type": "markdown",
   "id": "c06",
   "metadata": {},
   "source": "## 3. Text Preprocessing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07",
   "metadata": {},
   "outputs": [],
   "source": "def preprocess(text: str) -> str:\n    text = text.lower()\n    text = re.sub(r'<[^>]+>', ' ', text)  # strip HTML\n    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ndf['clean_text'] = df[TEXT_COL].astype(str).apply(preprocess)\ndf[['clean_text']].head(3)"
  },
  {
   "cell_type": "markdown",
   "id": "c08",
   "metadata": {},
   "source": "## 4. Train / Test Split"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09",
   "metadata": {},
   "outputs": [],
   "source": "X = df['clean_text']\ny = df[TARGET]\n\n# TODO: encode labels if they are strings, e.g.:\n# y = y.map({'positive': 1, 'negative': 0})\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(f'Train: {len(X_train)}, Test: {len(X_test)}')"
  },
  {
   "cell_type": "markdown",
   "id": "c10",
   "metadata": {},
   "source": "## 5. Model Training"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11",
   "metadata": {},
   "outputs": [],
   "source": "tfidf = TfidfVectorizer(ngram_range=(1, 2), max_features=50_000, sublinear_tf=True)\n\nmodels = {\n    'Naive Bayes': Pipeline([('tfidf', tfidf), ('clf', MultinomialNB())]),\n    'Logistic Regression': Pipeline([('tfidf', tfidf),\n                                    ('clf', LogisticRegression(max_iter=1000))]),\n    'LinearSVC': Pipeline([('tfidf', tfidf), ('clf', LinearSVC(max_iter=2000))]),\n}\n\nresults = {}\nfor name, pipe in models.items():\n    pipe.fit(X_train, y_train)\n    preds = pipe.predict(X_test)\n    results[name] = {'pipe': pipe, 'preds': preds}\n    print(f'\\n=== {name} ===')\n    print(classification_report(y_test, preds))"
  },
  {
   "cell_type": "markdown",
   "id": "c12",
   "metadata": {},
   "source": "## 6. Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13",
   "metadata": {},
   "outputs": [],
   "source": "# Confusion matrices\nfig, axes = plt.subplots(1, len(results), figsize=(5 * len(results), 4))\nfor ax, (name, res) in zip(axes, results.items()):\n    ConfusionMatrixDisplay.from_predictions(y_test, res['preds'], ax=ax)\n    ax.set_title(name)\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14",
   "metadata": {},
   "outputs": [],
   "source": "# Top TF-IDF terms per class (Logistic Regression)\nlr_pipe = results['Logistic Regression']['pipe']\nvocab = lr_pipe.named_steps['tfidf'].get_feature_names_out()\ncoef = lr_pipe.named_steps['clf'].coef_[0]\n\ntop_pos = pd.Series(coef, index=vocab).nlargest(15)\ntop_neg = pd.Series(coef, index=vocab).nsmallest(15)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\ntop_pos.sort_values().plot(kind='barh', ax=axes[0])\naxes[0].set_title('Top Positive Terms')\ntop_neg.sort_values().plot(kind='barh', ax=axes[1])\naxes[1].set_title('Top Negative Terms')\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "c15",
   "metadata": {},
   "source": "## 7. Conclusion\n\n| Model | Accuracy | F1 |\n|---|---|---|\n| *(fill after running)* | | |\n\n**Observations:**\n- \n\n**Next steps:**\n- Tune `max_features` and `ngram_range` in TF-IDF\n- Try character-level n-grams for noisy text\n- Explore pre-trained embeddings (GloVe, fastText)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}